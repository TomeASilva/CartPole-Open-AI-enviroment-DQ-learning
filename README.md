
## DQN Algorithm:
___
  - With replay buffers
  - With Target network
  - With a 2 hidden layer Neural Net as Q- value approximator
  - With parameters learnt using Semi-gradient-descent 
  
### The algorithm outline can be summarized by : 


![alt text][DQN]

[DQN]: https://github.com/TomeASilva/CartPole-Open-AI-enviroment-DQ-learning/blob/master/images/Q_learnig.png

Image taken from: CS 294-112 at UC Berkeley lecture slides\
See more at: http://rail.eecs.berkeley.edu/deeprlcourse/

 
 
  
